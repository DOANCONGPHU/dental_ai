# import tensorflow as tf
# from keras.preprocessing.image import ImageDataGenerator
# from keras.applications import MobileNetV2
# from keras.models import Model
# from keras.layers import Dense, GlobalAveragePooling2D, Dropout
# from keras.optimizers import Adam
# from keras.callbacks import EarlyStopping, ModelCheckpoint
# import numpy as np
# from sklearn.utils import class_weight

# # ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu
# train_dir = "../dataset/train"
# val_dir = "../dataset/val"
# test_dir = "../dataset/test"

# # C√°c tham s·ªë
# img_size = (224, 224)
# batch_size = 6
# num_classes = 6
# epochs = 25

# # TƒÉng c∆∞·ªùng d·ªØ li·ªáu (augment nh·∫π h∆°n)
# train_datagen = ImageDataGenerator(
#     rescale=1./255,
#     rotation_range=20,
#     zoom_range=0.2,
#     horizontal_flip=True,
#     width_shift_range=0.2,
#     height_shift_range=0.2,
#     brightness_range=[0.8, 1.2],
# )

# val_datagen = ImageDataGenerator(rescale=1./255)
# test_datagen = ImageDataGenerator(rescale=1./255)

# # Load d·ªØ li·ªáu
# train_generator = train_datagen.flow_from_directory(
#     train_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical"
# )

# val_generator = val_datagen.flow_from_directory(
#     val_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical"
# )

# test_generator = test_datagen.flow_from_directory(
#     test_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical",
#     shuffle=False
# )

# # T√≠nh class_weight
# class_weights = class_weight.compute_class_weight(
#     class_weight='balanced',
#     classes=np.unique(train_generator.classes),
#     y=train_generator.classes
# )
# class_weights_dict = dict(enumerate(class_weights))
# print("Class weights:", class_weights_dict)

# # Load MobileNetV2 v√† cho trainable t·∫•t c·∫£ layers
# base_model = MobileNetV2(input_shape=img_size + (3,), include_top=False, weights='imagenet')
# base_model.trainable = True  # <<< B·∫≠t trainable ngay t·ª´ ƒë·∫ßu

# # X√¢y m√¥ h√¨nh
# x = base_model.output
# x = GlobalAveragePooling2D()(x)
# x = Dropout(0.3)(x)
# predictions = Dense(num_classes, activation='softmax')(x)

# model = Model(inputs=base_model.input, outputs=predictions)

# # Compile
# model.compile(
#     optimizer=Adam(learning_rate=0.0001),
#     loss='categorical_crossentropy',
#     metrics=['accuracy']
# )

# # Callbacks
# earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
# checkpoint = ModelCheckpoint("best_mobilenetv2_model.h5", monitor='val_accuracy', save_best_only=True, verbose=1)

# # Train
# history = model.fit(
#     train_generator,
#     epochs=epochs,
#     validation_data=val_generator,
#     class_weight=class_weights_dict,
#     callbacks=[earlystop, checkpoint]
# )

# # Load l·∫°i model t·ªët nh·∫•t
# model = tf.keras.models.load_model("best_mobilenetv2_model.h5")

# # ƒê√°nh gi√° tr√™n test
# import sklearn.metrics as metrics

# y_pred = model.predict(test_generator)
# y_pred_classes = np.argmax(y_pred, axis=1)
# y_true = test_generator.classes

# print("\nüéØ Ma tr·∫≠n nh·∫ßm l·∫´n:")
# print(metrics.confusion_matrix(y_true, y_pred_classes))

# print("\nüéØ B√°o c√°o ph√¢n lo·∫°i:")
# print(metrics.classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))

# # L∆∞u m√¥ h√¨nh cu·ªëi c√πng
# model.save("oral_disease_model_mobilenetv2_final.h5")
# print("‚úÖ 90 Model saved as oral_disease_model_mobilenetv2_final.h5")


# import os
# import cv2
# import numpy as np
# import random
# from tqdm import tqdm
# from sklearn.utils import class_weight
# from keras.preprocessing.image import ImageDataGenerator
# from keras.applications import MobileNetV2
# from keras.models import Model
# from keras.layers import Dense, GlobalAveragePooling2D, Dropout
# from keras.optimizers import Adam
# from keras.callbacks import EarlyStopping, ModelCheckpoint
# import tensorflow as tf
# import matplotlib.pyplot as plt
# import seaborn as sns
# import sklearn.metrics as metrics

# # ====== C·∫§U H√åNH ======
# original_train_dir = r"D:\DO_AN\dataset\train"
# val_dir = r"D:\DO_AN\dataset\val"
# test_dir = r"D:\DO_AN\dataset\test"
# balanced_train_dir = r"D:\DO_AN\dataset_balanced\train"

# target_count = 1964
# img_size = (224, 224)
# batch_size = 6
# num_classes = 6
# epochs = 25

# # ====== TƒÇNG C∆Ø·ªúNG D·ªÆ LI·ªÜU CHO L·ªöP THI·∫æU ======
# augmenter = ImageDataGenerator(
#     rotation_range=20,
#     zoom_range=0.2,
#     horizontal_flip=True,
#     width_shift_range=0.2,
#     height_shift_range=0.2,
#     brightness_range=[0.8, 1.2],
#     fill_mode='nearest'
# )

# def balance_dataset():
#     print("üöÄ B·∫Øt ƒë·∫ßu tƒÉng c∆∞·ªùng ·∫£nh ƒë·ªÉ c√¢n b·∫±ng d·ªØ li·ªáu...")
#     os.makedirs(balanced_train_dir, exist_ok=True)

#     for class_name in os.listdir(original_train_dir):
#         input_path = os.path.join(original_train_dir, class_name)
#         output_path = os.path.join(balanced_train_dir, class_name)
#         os.makedirs(output_path, exist_ok=True)

#         images = [
#             f for f in os.listdir(input_path)
#             if f.lower().endswith(('.jpg', '.jpeg', '.png'))
#         ]

#         current_count = len(images)
#         needed = target_count - current_count

#         # Copy ·∫£nh g·ªëc tr∆∞·ªõc
#         for f in images:
#             src = os.path.join(input_path, f)
#             dst = os.path.join(output_path, f)
#             if not os.path.exists(dst):
#                 os.system(f'copy "{src}" "{dst}" >nul')

#         if needed <= 0:
#             continue

#         print(f"üîß L·ªõp '{class_name}': {current_count} ·∫£nh ‚Üí c·∫ßn tƒÉng th√™m {needed}")
#         i = 0
#         pbar = tqdm(total=needed, desc=f"TƒÉng ·∫£nh {class_name}")
#         while i < needed:
#             img_name = random.choice(images)
#             img_path = os.path.join(input_path, img_name)
#             img = cv2.imread(img_path)
#             if img is None:
#                 continue
#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#             img = cv2.resize(img, img_size)
#             img = np.expand_dims(img / 255.0, axis=0)

#             aug_iter = augmenter.flow(img, batch_size=1)
#             aug_img = next(aug_iter)[0]
#             aug_img_bgr = cv2.cvtColor((aug_img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

#             save_path = os.path.join(output_path, f"aug_{i}.jpg")
#             cv2.imwrite(save_path, aug_img_bgr)
#             i += 1
#             pbar.update(1)
#         pbar.close()
#     print("‚úÖ ƒê√£ ho√†n t·∫•t c√¢n b·∫±ng d·ªØ li·ªáu!\n")

# # ====== V·∫º BI·ªÇU ƒê·ªí TRAINING ======
# def plot_training_history(history):
#     acc = history.history['accuracy']
#     val_acc = history.history['val_accuracy']
#     loss = history.history['loss']
#     val_loss = history.history['val_loss']
#     epochs_range = range(len(acc))

#     plt.figure(figsize=(12, 5))

#     plt.subplot(1, 2, 1)
#     plt.plot(epochs_range, acc, label='Train Accuracy')
#     plt.plot(epochs_range, val_acc, label='Val Accuracy')
#     plt.legend(loc='lower right')
#     plt.title('Training & Validation Accuracy')

#     plt.subplot(1, 2, 2)
#     plt.plot(epochs_range, loss, label='Train Loss')
#     plt.plot(epochs_range, val_loss, label='Val Loss')
#     plt.legend(loc='upper right')
#     plt.title('Training & Validation Loss')

#     plt.tight_layout()
#     plt.savefig("training_history.png")
#     plt.show()

# # ====== V·∫º MA TR·∫¨N NH·∫¶M L·∫™N ======
# def plot_confusion_matrix(y_true, y_pred, class_names):
#     cm = metrics.confusion_matrix(y_true, y_pred)
#     plt.figure(figsize=(8, 6))
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
#                 xticklabels=class_names,
#                 yticklabels=class_names)
#     plt.ylabel('Actual')
#     plt.xlabel('Predicted')
#     plt.title('Confusion Matrix')
#     plt.tight_layout()
#     plt.savefig("confusion_matrix.png")
#     plt.show()

# # ====== TƒÇNG C∆Ø·ªúNG TR∆Ø·ªöC ======
# balance_dataset()

# # ====== LOAD D·ªÆ LI·ªÜU SAU TƒÇNG C∆Ø·ªúNG ======
# train_datagen = ImageDataGenerator(rescale=1./255)
# val_datagen = ImageDataGenerator(rescale=1./255)
# test_datagen = ImageDataGenerator(rescale=1./255)

# train_generator = train_datagen.flow_from_directory(
#     balanced_train_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical"
# )

# val_generator = val_datagen.flow_from_directory(
#     val_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical"
# )

# test_generator = test_datagen.flow_from_directory(
#     test_dir,
#     target_size=img_size,
#     batch_size=batch_size,
#     class_mode="categorical",
#     shuffle=False
# )

# # ====== T√çNH TR·ªåNG S·ªê L·ªöP ======
# class_weights = class_weight.compute_class_weight(
#     class_weight='balanced',
#     classes=np.unique(train_generator.classes),
#     y=train_generator.classes
# )
# class_weights_dict = dict(enumerate(class_weights))
# print("üìä Class weights:", class_weights_dict)

# # ====== M√î H√åNH MOBILENETV2 ======
# base_model = MobileNetV2(input_shape=img_size + (3,), include_top=False, weights='imagenet')
# base_model.trainable = True

# x = base_model.output
# x = GlobalAveragePooling2D()(x)
# x = Dropout(0.3)(x)
# predictions = Dense(num_classes, activation='softmax')(x)

# model = Model(inputs=base_model.input, outputs=predictions)

# model.compile(
#     optimizer=Adam(learning_rate=0.0001),
#     loss='categorical_crossentropy',
#     metrics=['accuracy']
# )

# # ====== TRAINING ======
# earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
# checkpoint = ModelCheckpoint("best_mobilenetv2_model.h5", monitor='val_accuracy', save_best_only=True, verbose=1)

# history = model.fit(
#     train_generator,
#     epochs=epochs,
#     validation_data=val_generator,
#     class_weight=class_weights_dict,
#     callbacks=[earlystop, checkpoint]
# )


# # ====== ƒê√ÅNH GI√Å M√î H√åNH ======
# model = tf.keras.models.load_model("best_mobilenetv2_model.h5")

# y_pred = model.predict(test_generator)
# y_pred_classes = np.argmax(y_pred, axis=1)
# y_true = test_generator.classes
# class_names = list(test_generator.class_indices.keys())

# # ====== IN B√ÅO C√ÅO 1 L·∫¶N ======
# print("\nüéØ Ma tr·∫≠n nh·∫ßm l·∫´n:")
# print(metrics.confusion_matrix(y_true, y_pred_classes))

# print("\nüéØ B√°o c√°o ph√¢n lo·∫°i:")
# print(metrics.classification_report(y_true, y_pred_classes, target_names=class_names))

# # ====== V·∫º BI·ªÇU ƒê·ªí ======
# plot_training_history(history)
# plot_confusion_matrix(y_true, y_pred_classes, class_names)

# # ====== L∆ØU M√î H√åNH ======
# model.save("oral_disease_model_mobilenetv2_final.h5")
# print("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: oral_disease_model_mobilenetv2_final.h5")

# /////////////////////////////////////////////////////


import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import MobileNetV2
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D, Dropout
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.utils import class_weight
from sklearn.metrics import confusion_matrix, classification_report
from collections import Counter
import pickle
import zipfile

# ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu

model_dir = r"D:\DO_AN\model"
train_dir = r"D:\DO_AN\dataset\train"
val_dir = r"D:\DO_AN\dataset\val"
test_dir = r"D:\DO_AN\dataset\test"
# Ki·ªÉm tra th∆∞ m·ª•c
os.makedirs(model_dir, exist_ok=True)
for directory in [train_dir, val_dir, test_dir]:
    if not os.path.exists(directory):
        raise FileNotFoundError(f"Directory {directory} does not exist")

# C√°c tham s·ªë
img_size = (224, 224)
batch_size = 6
num_classes = 6
epochs = 25

# Ki·ªÉm tra ph√¢n b·ªë l·ªõp
train_generator_temp = ImageDataGenerator(rescale=1./255).flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical"
)
print("Ph√¢n b·ªë l·ªõp trong t·∫≠p hu·∫•n luy·ªán:", Counter(train_generator_temp.classes))

# TƒÉng c∆∞·ªùng d·ªØ li·ªáu
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.8, 1.2],
)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical"
)
val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical"
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    shuffle=False
)

# T√≠nh class_weight
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weights_dict = dict(enumerate(class_weights))
print("Class weights:", class_weights_dict)

# Load MobileNetV2 v√† ƒë√≥ng bƒÉng c√°c t·∫ßng ban ƒë·∫ßu
base_model = MobileNetV2(input_shape=img_size + (3,), include_top=False, weights='imagenet')
base_model.trainable = False

# X√¢y m√¥ h√¨nh
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
predictions = Dense(num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# Compile
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Callbacks
earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
checkpoint = ModelCheckpoint(
    os.path.join(model_dir, "best_mobilenetv2_model.h5"),
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)
checkpoint_periodic = ModelCheckpoint(
    os.path.join(model_dir, "mobilenetv2_epoch_{epoch:02d}.h5"),
    monitor='val_loss',
    save_best_only=False,
    verbose=1,
    period=5
)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)

# Train giai ƒëo·∫°n 1
history_phase1 = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator,
    class_weight=class_weights_dict,
    callbacks=[earlystop, checkpoint, checkpoint_periodic, reduce_lr]
)

# Giai ƒëo·∫°n 2: M·ªü kh√≥a to√†n b·ªô m√¥ h√¨nh ƒë·ªÉ fine-tune
base_model.trainable = True
model.compile(
    optimizer=Adam(learning_rate=15e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train giai ƒëo·∫°n 2
history_phase2 = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=val_generator,
    class_weight=class_weights_dict,
    callbacks=[earlystop, checkpoint, checkpoint_periodic, reduce_lr]
)

# L∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán
with open(os.path.join(model_dir, 'mobilenetv2_history.pkl'), 'wb') as f:
    pickle.dump({'phase1': history_phase1.history, 'phase2': history_phase2.history}, f)

# V·∫Ω bi·ªÉu ƒë·ªì loss/accuracy
plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history_phase2.history['accuracy'], label='Train Accuracy')
plt.plot(history_phase2.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history_phase2.history['loss'], label='Train Loss')
plt.plot(history_phase2.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.savefig(os.path.join(model_dir, "training_plot_mobilenetv2.png"))
plt.show()

# ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra
model = tf.keras.models.load_model(os.path.join(model_dir, "best_mobilenetv2_model.h5"))
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

print("\nüéØ Ma tr·∫≠n nh·∫ßm l·∫´n:")
conf_matrix = confusion_matrix(y_true, y_pred_classes)
print(conf_matrix)

print("\nüéØ B√°o c√°o ph√¢n lo·∫°i:")
print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))

# V·∫Ω ma tr·∫≠n nh·∫ßm l·∫´n
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.savefig(os.path.join(model_dir, "confusion_matrix_mobilenetv2.png"))
plt.show()

# L∆∞u m√¥ h√¨nh cu·ªëi c√πng
model.save(os.path.join(model_dir, "oral_disease_model_mobilenetv2_tamthoi.h5"))
print(f"‚úÖ Model saved as {os.path.join(model_dir, 'oral_disease_model_mobilenetv2_final.h5')}")